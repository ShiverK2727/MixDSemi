#!/usr/bin/env python3

"""

ä¸“é—¨é’ˆå¯¹GPT5-80æè¿°çš„åŸŸæ„ŸçŸ¥èƒ½åŠ›å¿«é€Ÿåˆ†æè„šæœ¬

"""



import os

import sys

import torch

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.manifold import TSNE

from sklearn.decomposition import PCA

import warnings

warnings.filterwarnings('ignore')



# è®¾ç½®matplotlibåç«¯å’Œä¸­æ–‡å­—ä½“

import matplotlib

matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

plt.rcParams['font.size'] = 10

plt.rcParams['figure.dpi'] = 100



def quick_domain_analysis(dataset_name='ProstateSlice',

                         llm='DeepSeek',

                         describe_nums=80,

                         preprocess_root='/app/MixDSemi/SynFoCLIP/preprocess'):

    """

    å¿«é€Ÿåˆ†ææŒ‡å®šæ•°æ®é›†çš„åŸŸæ„ŸçŸ¥èƒ½åŠ›

    """

    print(f"\nğŸ” Analyzing {dataset_name} with {llm}-{describe_nums}")

    print("-" * 50)

   

    # æ£€æŸ¥æ•°æ®è·¯å¾„

    dataset_path = os.path.join(preprocess_root, dataset_name)

    if not os.path.exists(dataset_path):

        print(f"âŒ Dataset path not found: {dataset_path}")

        return None

   

    # åŠ è½½æ‰€æœ‰åŸŸçš„æ•°æ®

    domain_data = {}

    domains = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]

   

    print(f"Found domains: {domains}")

   

    for domain in domains:

        score_file = os.path.join(dataset_path, domain, f"{llm}_{describe_nums}.pt")

        if os.path.exists(score_file):

            print(f"ğŸ“‚ Loading {domain}...")

            try:

                image_text_match = torch.load(score_file, map_location='cpu')

                images = list(image_text_match.keys())

                scores = torch.stack(list(image_text_match.values())).numpy()

               

                domain_data[domain] = {

                    'images': images,

                    'scores': scores

                }

                print(f"   âœ… {len(images)} images, {scores.shape[1]} text features")

            except Exception as e:

                print(f"   âŒ Error loading {domain}: {e}")

        else:

            print(f"   âš ï¸ Score file not found for {domain}: {score_file}")

   

    if not domain_data:

        print("âŒ No data loaded!")

        return None

   

    # å‡†å¤‡æ•°æ®è¿›è¡Œt-SNE

    print("\nğŸ§® Computing t-SNE...")

    all_scores = []

    all_labels = []

    all_domains = []

   

    for domain, data in domain_data.items():

        all_scores.append(data['scores'])

        all_labels.extend([domain] * len(data['images']))

        all_domains.append(domain)

   

    all_scores = np.vstack(all_scores)

    print(f"Total samples: {all_scores.shape[0]}, Features: {all_scores.shape[1]}")

   

    # å¦‚æœç‰¹å¾å¤ªå¤šï¼Œå…ˆPCAé™ç»´

    if all_scores.shape[1] > 50:

        print("   Applying PCA preprocessing...")

        pca = PCA(n_components=50, random_state=42)

        all_scores = pca.fit_transform(all_scores)

   

    # t-SNEé™ç»´

    print("   Running t-SNE...")

    perplexity = min(30, max(5, len(all_scores)//4))

    try:

        tsne = TSNE(n_components=2, perplexity=perplexity,

                   random_state=42, max_iter=1000)

    except TypeError:

        # å…¼å®¹è€ç‰ˆæœ¬sklearn

        tsne = TSNE(n_components=2, perplexity=perplexity,

                   random_state=42)

    tsne_coords = tsne.fit_transform(all_scores)

   

    # ç»˜åˆ¶ç»“æœ

    print("\nğŸ“Š Creating visualization...")

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

   

    # ä¸ºæ¯ä¸ªåŸŸåˆ†é…é¢œè‰²

    colors = plt.cm.Set1(np.linspace(0, 1, len(all_domains)))

    domain_colors = dict(zip(all_domains, colors))

   

    # å·¦å›¾: t-SNEæ•£ç‚¹å›¾

    ax1 = axes[0]

    start_idx = 0

    for domain, data in domain_data.items():

        end_idx = start_idx + len(data['images'])

        coords = tsne_coords[start_idx:end_idx]

       

        ax1.scatter(coords[:, 0], coords[:, 1],

                   c=[domain_colors[domain]],

                   label=f'{domain} (n={len(coords)})',

                   alpha=0.7, s=30)

        start_idx = end_idx

   

    ax1.set_title(f'{dataset_name} Domain Distribution\\n{llm} with {describe_nums} descriptions')

    ax1.set_xlabel('t-SNE Component 1')

    ax1.set_ylabel('t-SNE Component 2')

    ax1.legend()

    ax1.grid(True, alpha=0.3)

   

    # å³å›¾: åŸŸé—´è·ç¦»åˆ†æ

    ax2 = axes[1]

   

    # è®¡ç®—åŸŸä¸­å¿ƒå’Œè·ç¦»çŸ©é˜µ

    domain_centers = {}

    start_idx = 0

    for domain, data in domain_data.items():

        end_idx = start_idx + len(data['images'])

        coords = tsne_coords[start_idx:end_idx]

        domain_centers[domain] = np.mean(coords, axis=0)

        start_idx = end_idx

   

    # è·ç¦»çŸ©é˜µ

    n_domains = len(all_domains)

    distance_matrix = np.zeros((n_domains, n_domains))

   

    for i, domain1 in enumerate(all_domains):

        for j, domain2 in enumerate(all_domains):

            if i != j:

                dist = np.linalg.norm(domain_centers[domain1] - domain_centers[domain2])

                distance_matrix[i, j] = dist

   

    sns.heatmap(distance_matrix, annot=True, fmt='.2f',

               xticklabels=all_domains, yticklabels=all_domains,

               cmap='YlOrRd', ax=ax2)

    ax2.set_title('Inter-Domain Distance Matrix')

   

    plt.tight_layout()

   

    # ä¿å­˜å›¾ç‰‡

    output_file = f"{dataset_name}_{llm}_{describe_nums}_domain_analysis.png"

    plt.savefig(output_file, dpi=300, bbox_inches='tight')

    plt.close()

   

    print(f"ğŸ’¾ Saved plot: {output_file}")

   

    # è®¡ç®—å’Œæ‰“å°åˆ†ç¦»åº¦æŒ‡æ ‡

    print("\nğŸ“ˆ Domain Separation Analysis:")

    print("-" * 30)

   

    # åŸŸå†…ç´§å¯†åº¦

    intra_spreads = []

    start_idx = 0

    for domain, data in domain_data.items():

        end_idx = start_idx + len(data['images'])

        coords = tsne_coords[start_idx:end_idx]

        center = domain_centers[domain]

        spread = np.mean(np.linalg.norm(coords - center, axis=1))

        intra_spreads.append(spread)

        print(f"{domain:12}: {len(coords):3d} samples, spread: {spread:.3f}")

        start_idx = end_idx

   

    # åŸŸé—´è·ç¦»

    inter_distances = []

    for i, domain1 in enumerate(all_domains):

        for j, domain2 in enumerate(all_domains):

            if i < j:

                dist = np.linalg.norm(domain_centers[domain1] - domain_centers[domain2])

                inter_distances.append(dist)

   

    avg_intra_spread = np.mean(intra_spreads)

    avg_inter_distance = np.mean(inter_distances)

    separation_ratio = avg_inter_distance / avg_intra_spread if avg_intra_spread > 0 else 0

   

    print(f"\nSummary:")

    print(f"Avg intra-domain spread: {avg_intra_spread:.3f}")

    print(f"Avg inter-domain distance: {avg_inter_distance:.3f}")

    print(f"Separation ratio: {separation_ratio:.3f}")

   

    if separation_ratio > 2.0:

        print("âœ… Excellent domain separation!")

    elif separation_ratio > 1.5:

        print("ğŸŸ¡ Good domain separation")

    elif separation_ratio > 1.0:

        print("ğŸŸ  Moderate domain separation")

    else:

        print("âŒ Poor domain separation")

   

    return {

        'dataset': dataset_name,

        'separation_ratio': separation_ratio,

        'avg_intra_spread': avg_intra_spread,

        'avg_inter_distance': avg_inter_distance,

        'n_domains': len(all_domains),

        'total_samples': all_scores.shape[0],

        'plot_file': output_file

    }



def analyze_all_available_datasets():

    """åˆ†ææ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†"""

    preprocess_root = '/app/MixDSemi/SynFoCLIP/preprocess'

    available_datasets = [d for d in os.listdir(preprocess_root)

                         if os.path.isdir(os.path.join(preprocess_root, d))]

   

    print(f"ğŸ” Found datasets: {available_datasets}")

   

    results = []

    for dataset in available_datasets:

        try:

            result = quick_domain_analysis(dataset)

            if result:

                results.append(result)

        except Exception as e:

            print(f"âŒ Error analyzing {dataset}: {e}")

   

    # æ€»ç»“æ‰€æœ‰ç»“æœ

    if results:

        print(f"\n{'='*60}")

        print("ğŸ† OVERALL DOMAIN AWARENESS SUMMARY")

        print('='*60)

       

        # æŒ‰åˆ†ç¦»åº¦æ’åº

        results.sort(key=lambda x: x['separation_ratio'], reverse=True)

       

        for i, result in enumerate(results, 1):

            status = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "ğŸ“Š"

            print(f"{status} {result['dataset']:15} | Ratio: {result['separation_ratio']:5.2f} | "

                  f"{result['n_domains']} domains | {result['total_samples']} samples")

   

    return results



if __name__ == "__main__":

    if len(sys.argv) > 1:

        dataset_name = sys.argv[1]

        print(f"Analyzing specific dataset: {dataset_name}")

        quick_domain_analysis(dataset_name)

    else:

        print("Analyzing all available datasets...")

        analyze_all_available_datasets()

