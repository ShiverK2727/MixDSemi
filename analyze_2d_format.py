#!/usr/bin/env python3
"""
æ”¯æŒæ–°äºŒç»´æ ¼å¼çš„t-SNEåŸŸæ„ŸçŸ¥åˆ†æ
æ”¯æŒåˆ†ç¦»å†…å®¹ç±»å‹å’Œé£æ ¼æç¤ºåˆ†æ
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibåç«¯
import matplotlib
matplotlib.use('Agg')
plt.rcParams['font.size'] = 10
plt.rcParams['figure.dpi'] = 100

def analyze_2d_format_domain_awareness(dataset_name='ProstateSlice', 
                                     llm='GPT5', 
                                     describe_nums=80,
                                     preprocess_root='/app/MixDSemi/SynFoCLIP/preprocess',
                                     separate_style=True,
                                     style_at_end=True):
    """
    åˆ†ææ–°äºŒç»´æ ¼å¼çš„åŸŸæ„ŸçŸ¥èƒ½åŠ›ï¼Œæ”¯æŒé£æ ¼æç¤ºåˆ†ç¦»
    
    Args:
        separate_style: æ˜¯å¦åˆ†ç¦»é£æ ¼æç¤ºè¿›è¡Œå•ç‹¬åˆ†æ
        style_at_end: é£æ ¼æç¤ºæ˜¯å¦åœ¨æœ€åä¸€ä¸ªtypeä½ç½®
    """
    print(f"\nğŸ” Analyzing {dataset_name} with {llm}-{describe_nums} (2D Format)")
    print("-" * 60)
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    dataset_path = os.path.join(preprocess_root, dataset_name)
    if not os.path.exists(dataset_path):
        print(f"âŒ Dataset path not found: {dataset_path}")
        return None
    
    # åŠ è½½æ‰€æœ‰åŸŸçš„æ•°æ®
    domain_data = {}
    domains = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
    
    print(f"Found domains: {domains}")
    
    data_format = None  # æ£€æµ‹æ•°æ®æ ¼å¼
    
    for domain in domains:
        score_file = os.path.join(dataset_path, domain, f"{llm}_{describe_nums}.pt")
        if os.path.exists(score_file):
            print(f"ğŸ“‚ Loading {domain}...")
            try:
                image_text_match = torch.load(score_file, map_location='cpu')
                images = list(image_text_match.keys())
                
                # æ£€æµ‹æ•°æ®æ ¼å¼
                sample_data = list(image_text_match.values())[0]
                if len(sample_data.shape) == 1:
                    print(f"   ğŸ“Š Detected 1D format: {sample_data.shape}")
                    data_format = '1D'
                    scores = torch.stack(list(image_text_match.values())).numpy()
                elif len(sample_data.shape) == 2:
                    print(f"   ğŸ“Š Detected 2D format: {sample_data.shape}")
                    data_format = '2D'
                    total_types, desc_nums = sample_data.shape
                    print(f"   ğŸ“‹ Types: {total_types}, Descriptions per type: {desc_nums}")
                    
                    # æ”¶é›†2Dæ•°æ®
                    scores_2d = torch.stack(list(image_text_match.values())).numpy()  # [n_images, total_types, desc_nums]
                    
                    if separate_style and style_at_end:
                        # åˆ†ç¦»é£æ ¼æç¤ºå’Œå†…å®¹ç±»å‹
                        content_scores = scores_2d[:, :-1, :]  # [n_images, total_types-1, desc_nums]
                        style_scores = scores_2d[:, -1, :]     # [n_images, desc_nums]
                        
                        print(f"   ğŸ¨ Style scores shape: {style_scores.shape}")
                        print(f"   ğŸ“ Content scores shape: {content_scores.shape}")
                        
                        # é‡å¡‘å†…å®¹ç±»å‹åˆ†æ•°ä¸ºåˆ†ææ ¼å¼
                        content_flat = content_scores.reshape(len(images), -1)  # [n_images, (total_types-1)*desc_nums]
                        scores = content_flat  # åªåˆ†æå†…å®¹ç±»å‹
                        
                        # ä¿å­˜é£æ ¼åˆ†æ•°ç”¨äºåç»­åˆ†æ
                        domain_data[domain] = {
                            'images': images,
                            'content_scores': scores,
                            'style_scores': style_scores,
                            'original_2d': scores_2d
                        }
                    else:
                        # ä¸åˆ†ç¦»ï¼Œå±•å¹³æ•´ä¸ª2Dæ•°æ®
                        scores = scores_2d.reshape(len(images), -1)  # [n_images, total_types*desc_nums]
                        domain_data[domain] = {
                            'images': images,
                            'scores': scores,
                            'original_2d': scores_2d
                        }
                else:
                    print(f"   âŒ Unsupported data format: {sample_data.shape}")
                    continue
                
                if not separate_style:
                    domain_data[domain] = {
                        'images': images,
                        'scores': scores
                    }
                
                print(f"   âœ… {len(images)} images loaded successfully")
                
            except Exception as e:
                print(f"   âŒ Error loading {domain}: {e}")
        else:
            print(f"   âš ï¸ Score file not found for {domain}: {score_file}")
    
    if not domain_data:
        print("âŒ No data loaded!")
        return None
    
    # é€‰æ‹©ç”¨äºt-SNEçš„æ•°æ®
    analysis_data = {}
    if separate_style and 'content_scores' in list(domain_data.values())[0]:
        print(f"\nğŸ¯ Analyzing CONTENT types only (excluding style)")
        for domain, data in domain_data.items():
            analysis_data[domain] = {
                'images': data['images'],
                'scores': data['content_scores']
            }
    else:
        print(f"\nğŸ¯ Analyzing ALL types together")
        analysis_data = domain_data
    
    # æ‰§è¡Œt-SNEåˆ†æ
    tsne_results = compute_tsne_analysis(analysis_data)
    if not tsne_results:
        return None
    
    # åˆ›å»ºå¯è§†åŒ–
    fig = create_enhanced_visualization(tsne_results, dataset_name, llm, describe_nums, separate_style)
    
    # ä¿å­˜ç»“æœ
    suffix = "_content_only" if separate_style else "_all_types"
    output_file = f"{dataset_name}_{llm}_{describe_nums}_2D{suffix}.png"
    fig.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    print(f"ğŸ’¾ Saved analysis: {output_file}")
    
    # å¦‚æœæœ‰é£æ ¼æ•°æ®ï¼Œé¢å¤–åˆ†æé£æ ¼åˆ†å¸ƒ
    if separate_style and 'style_scores' in list(domain_data.values())[0]:
        analyze_style_distribution(domain_data, dataset_name, llm, describe_nums)
    
    return tsne_results

def compute_tsne_analysis(analysis_data):
    """è®¡ç®—t-SNEåˆ†æ"""
    print(f"\nğŸ§® Computing t-SNE...")
    
    # å‡†å¤‡æ•°æ®
    all_scores = []
    all_labels = []
    all_domains = list(analysis_data.keys())
    
    for domain, data in analysis_data.items():
        all_scores.append(data['scores'])
        all_labels.extend([domain] * len(data['images']))
    
    all_scores = np.vstack(all_scores)
    print(f"Total samples: {all_scores.shape[0]}, Features: {all_scores.shape[1]}")
    
    # PCAé¢„å¤„ç†
    if all_scores.shape[1] > 50:
        print("   Applying PCA preprocessing...")
        pca = PCA(n_components=50, random_state=42)
        all_scores = pca.fit_transform(all_scores)
        print(f"   Reduced to {all_scores.shape[1]} dimensions")
    
    # t-SNEé™ç»´
    print("   Running t-SNE...")
    perplexity = min(30, max(5, len(all_scores)//4))
    try:
        tsne = TSNE(n_components=2, perplexity=perplexity, 
                   random_state=42, max_iter=1000)
    except TypeError:
        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)
    
    tsne_coords = tsne.fit_transform(all_scores)
    
    # é‡ç»„ç»“æœ
    results = {}
    start_idx = 0
    for domain, data in analysis_data.items():
        end_idx = start_idx + len(data['images'])
        results[domain] = {
            'images': data['images'],
            'tsne_coords': tsne_coords[start_idx:end_idx]
        }
        start_idx = end_idx
    
    return results

def create_enhanced_visualization(tsne_results, dataset_name, llm, describe_nums, separate_style):
    """åˆ›å»ºå¢å¼ºçš„å¯è§†åŒ–"""
    print(f"\nğŸ“Š Creating enhanced visualization...")
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'{dataset_name} - Domain Analysis (2D Format)\\n{llm} with {describe_nums} descriptions' + 
                (f' - Content Only' if separate_style else ' - All Types'), fontsize=14)
    
    # ä¸ºæ¯ä¸ªåŸŸåˆ†é…é¢œè‰²
    domains = list(tsne_results.keys())
    colors = plt.cm.Set1(np.linspace(0, 1, len(domains)))
    domain_colors = dict(zip(domains, colors))
    
    # 1. t-SNEæ•£ç‚¹å›¾
    ax1 = axes[0, 0]
    for domain, data in tsne_results.items():
        coords = data['tsne_coords']
        ax1.scatter(coords[:, 0], coords[:, 1], 
                   c=[domain_colors[domain]], 
                   label=f'{domain} (n={len(coords)})',
                   alpha=0.7, s=30)
    
    ax1.set_title('t-SNE Domain Distribution')
    ax1.set_xlabel('t-SNE Component 1')
    ax1.set_ylabel('t-SNE Component 2')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. åŸŸé—´è·ç¦»çŸ©é˜µ
    ax2 = axes[0, 1]
    domain_centers = {}
    for domain, data in tsne_results.items():
        coords = data['tsne_coords']
        domain_centers[domain] = np.mean(coords, axis=0)
    
    n_domains = len(domains)
    distance_matrix = np.zeros((n_domains, n_domains))
    
    for i, domain1 in enumerate(domains):
        for j, domain2 in enumerate(domains):
            if i != j:
                dist = np.linalg.norm(domain_centers[domain1] - domain_centers[domain2])
                distance_matrix[i, j] = dist
    
    sns.heatmap(distance_matrix, annot=True, fmt='.2f',
               xticklabels=domains, yticklabels=domains,
               cmap='YlOrRd', ax=ax2)
    ax2.set_title('Inter-Domain Distance Matrix')
    
    # 3. åŸŸå†…ç´§å¯†åº¦åˆ†æ
    ax3 = axes[1, 0]
    spreads = []
    domain_names = []
    
    for domain, data in tsne_results.items():
        coords = data['tsne_coords']
        center = domain_centers[domain]
        spread = np.mean(np.linalg.norm(coords - center, axis=1))
        spreads.append(spread)
        domain_names.append(domain)
    
    bars = ax3.bar(range(len(spreads)), spreads, color=[domain_colors[d] for d in domain_names])
    ax3.set_xticks(range(len(domain_names)))
    ax3.set_xticklabels(domain_names, rotation=45)
    ax3.set_title('Intra-Domain Spread')
    ax3.set_ylabel('Average Distance from Center')
    
    # 4. åˆ†ç¦»åº¦æŒ‡æ ‡
    ax4 = axes[1, 1]
    
    # è®¡ç®—åˆ†ç¦»åº¦æŒ‡æ ‡
    avg_intra_spread = np.mean(spreads)
    
    inter_distances = []
    for i, domain1 in enumerate(domains):
        for j, domain2 in enumerate(domains):
            if i < j:
                dist = np.linalg.norm(domain_centers[domain1] - domain_centers[domain2])
                inter_distances.append(dist)
    
    avg_inter_distance = np.mean(inter_distances)
    separation_ratio = avg_inter_distance / avg_intra_spread if avg_intra_spread > 0 else 0
    
    # ç»˜åˆ¶æŒ‡æ ‡
    metrics = ['Intra-Spread', 'Inter-Distance', 'Separation Ratio']
    values = [avg_intra_spread, avg_inter_distance, separation_ratio]
    
    bars = ax4.bar(metrics, values, color=['skyblue', 'lightcoral', 'lightgreen'])
    ax4.set_title('Separation Metrics')
    ax4.set_ylabel('Value')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{value:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    return fig

def analyze_style_distribution(domain_data, dataset_name, llm, describe_nums):
    """åˆ†æé£æ ¼æç¤ºçš„åˆ†å¸ƒ"""
    print(f"\nğŸ¨ Analyzing Style Distribution...")
    
    # æ”¶é›†æ‰€æœ‰é£æ ¼åˆ†æ•°
    all_style_scores = []
    style_labels = []
    
    for domain, data in domain_data.items():
        style_scores = data['style_scores']  # [n_images, desc_nums]
        all_style_scores.append(style_scores)
        style_labels.extend([domain] * len(style_scores))
    
    all_style_scores = np.vstack(all_style_scores)
    print(f"Style analysis: {all_style_scores.shape[0]} samples, {all_style_scores.shape[1]} style features")
    
    # è®¡ç®—æ¯ä¸ªåŸŸçš„é£æ ¼ç»Ÿè®¡
    print(f"\nğŸ“ˆ Style Statistics by Domain:")
    for domain, data in domain_data.items():
        style_scores = data['style_scores']
        mean_style = np.mean(style_scores)
        std_style = np.std(style_scores)
        max_style = np.max(style_scores)
        
        print(f"   {domain:12}: mean={mean_style:.4f}, std={std_style:.4f}, max={max_style:.4f}")

if __name__ == "__main__":
    # æµ‹è¯•æ–°çš„åˆ†æå‡½æ•°
    if len(sys.argv) > 1:
        dataset_name = sys.argv[1]
        separate_style = len(sys.argv) > 2 and sys.argv[2].lower() == 'true'
        analyze_2d_format_domain_awareness(dataset_name, separate_style=separate_style)
    else:
        print("Usage: python script.py <dataset_name> [separate_style]")
        print("Example: python script.py ProstateSlice true")